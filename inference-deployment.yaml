apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "23"
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app.kubernetes.io/instance":"onyx-prod"},"name":"inference-model-server-deployment","namespace":"danswer"},"spec":{"selector":{"matchLabels":{"app":"inference-model-server"}},"template":{"metadata":{"labels":{"app":"inference-model-server"}},"spec":{"containers":[{"command":["uvicorn","model_server.main:app","--host","0.0.0.0","--port","9000"],"envFrom":[{"configMapRef":{"name":"env-configmap"}},{"secretRef":{"name":"onyx-secrets"}}],"image":"onyxdotapp/onyx-model-server-cloud:v0.20.0-cloud.34","imagePullPolicy":"Always","name":"inference-model-server","ports":[{"containerPort":9000}],"readinessProbe":{"failureThreshold":6,"httpGet":{"path":"/api/health","port":9000},"initialDelaySeconds":60,"periodSeconds":60},"resources":{"limits":{"cpu":"2","memory":"8Gi"},"requests":{"cpu":"1000m","memory":"4Gi"}}}]}}}}
  creationTimestamp: "2024-12-19T00:50:55Z"
  generation: 34
  labels:
    app.kubernetes.io/instance: onyx-prod
  name: inference-model-server-deployment
  namespace: danswer
  resourceVersion: "97410115"
  uid: 5819d282-4ddd-4c7e-8285-698775bf8340
spec:
  progressDeadlineSeconds: 600
  replicas: 4
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: inference-model-server
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      annotations:
        kubectl.kubernetes.io/restartedAt: "2025-03-24T16:13:05-07:00"
      creationTimestamp: null
      labels:
        app: inference-model-server
    spec:
      containers:
      - command:
        - uvicorn
        - model_server.main:app
        - --host
        - 0.0.0.0
        - --port
        - "9000"
        envFrom:
        - configMapRef:
            name: env-configmap
        - secretRef:
            name: onyx-secrets
        image: onyxdotapp/onyx-model-server-cloud:v0.20.0-cloud.34
        imagePullPolicy: Always
        name: inference-model-server
        ports:
        - containerPort: 9000
          protocol: TCP
        readinessProbe:
          failureThreshold: 6
          httpGet:
            path: /api/health
            port: 9000
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 60
          successThreshold: 1
          timeoutSeconds: 1
        resources:
          limits:
            cpu: "2"
            memory: 8Gi
          requests:
            cpu: "1"
            memory: 4Gi
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
status:
  availableReplicas: 4
  conditions:
  - lastTransitionTime: "2025-02-04T02:14:45Z"
    lastUpdateTime: "2025-02-04T02:14:45Z"
    message: Deployment has minimum availability.
    reason: MinimumReplicasAvailable
    status: "True"
    type: Available
  - lastTransitionTime: "2025-02-14T02:43:06Z"
    lastUpdateTime: "2025-03-24T23:15:36Z"
    message: ReplicaSet "inference-model-server-deployment-65cd4f5b46" has successfully
      progressed.
    reason: NewReplicaSetAvailable
    status: "True"
    type: Progressing
  observedGeneration: 34
  readyReplicas: 4
  replicas: 4
  updatedReplicas: 4
