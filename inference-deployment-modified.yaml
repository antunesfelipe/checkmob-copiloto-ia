apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "23"
  labels:
    app.kubernetes.io/instance: onyx-prod
  name: inference-model-server-deployment
  namespace: danswer
spec:
  progressDeadlineSeconds: 600
  replicas: 4
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: inference-model-server
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      annotations:
        kubectl.kubernetes.io/restartedAt: "2025-03-24T16:13:05-07:00"
      labels:
        app: inference-model-server
    spec:
      containers:
        - command:
            - uvicorn
            - model_server.main:app
            - --host
            - 0.0.0.0
            - --port
            - "9000"
          envFrom:
            - configMapRef:
                name: env-configmap
            - secretRef:
                name: onyx-secrets
          image: onyxdotapp/onyx-model-server-cloud:v0.20.0-cloud.34
          imagePullPolicy: Always
          name: inference-model-server
          ports:
            - containerPort: 9000
              protocol: TCP
          readinessProbe:
            failureThreshold: 6
            httpGet:
              path: /api/health
              port: 9000
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 60
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              cpu: "2"
              memory: 8Gi
            requests:
              cpu: "1"
              memory: 4Gi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
      tolerations:
        - key: "nvidia.com/gpu"
          operator: "Equal"
          value: "1"
          effect: "NoSchedule"
